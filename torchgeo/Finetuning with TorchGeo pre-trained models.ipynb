{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8eee21cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.models import ResNet18_Weights, ResNet50_Weights, ViTSmall16_Weights\n",
    "from torchgeo.datasets import EuroSAT\n",
    "from torchgeo.models.api import list_models, get_model_weights, get_model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "724be920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18\n",
      "\t ResNet18_Weights.SENTINEL2_ALL_MOCO\n",
      "\t ResNet18_Weights.SENTINEL2_RGB_MOCO\n",
      "\t ResNet18_Weights.SENTINEL2_RGB_SECO\n",
      "resnet50\n",
      "\t ResNet50_Weights.SENTINEL1_ALL_MOCO\n",
      "\t ResNet50_Weights.SENTINEL2_ALL_MOCO\n",
      "\t ResNet50_Weights.SENTINEL2_RGB_MOCO\n",
      "\t ResNet50_Weights.SENTINEL2_ALL_DINO\n",
      "\t ResNet50_Weights.SENTINEL2_RGB_SECO\n",
      "vit_small_patch16_224\n",
      "\t ViTSmall16_Weights.SENTINEL2_ALL_MOCO\n",
      "\t ViTSmall16_Weights.SENTINEL2_ALL_DINO\n"
     ]
    }
   ],
   "source": [
    "for model_name in list_models():\n",
    "    print(model_name)\n",
    "    for weights in get_model_weights(model_name):\n",
    "        print(\"\\t\", weights)\n",
    "        model = get_model(model_name, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ea8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686f3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\"resnet50\", weights=None, in_chans=13).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ec7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\"resnet50\", weights=ResNet50_Weights.SENTINEL2_ALL_MOCO).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd33b62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weights(url='https://huggingface.co/torchgeo/resnet50_sentinel2_all_moco/resolve/main/resnet50_sentinel2_all_moco.pth', transforms=AugmentationSequential(\n",
       "  (augs): AugmentationSequential(\n",
       "    (Resize_0): Resize(Resize(output_size=256, p=1.0, p_batch=1.0, same_on_batch=True, size=256, side=short, resample=bilinear, align_corners=True, antialias=False))\n",
       "    (CenterCrop_1): CenterCrop(CenterCrop(p=1.0, p_batch=1.0, same_on_batch=True, resample=bilinear, cropping_mode=slice, align_corners=True, size=(224, 224), padding_mode=zeros))\n",
       "  )\n",
       "), meta={'dataset': 'SSL4EO-S12', 'in_chans': 13, 'model': 'resnet50', 'publication': 'https://arxiv.org/abs/2211.07044', 'repo': 'https://github.com/zhu-xlab/SSL4EO-S12', 'ssl_method': 'moco'})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet50_Weights.SENTINEL2_ALL_MOCO.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5ca72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 512\n",
    "model = create_feature_extractor(model, return_nodes=[\"global_pool\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63a576c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_means = torch.tensor(\n",
    "    [\n",
    "        1354.40546513,\n",
    "        1118.24399958,\n",
    "        1042.92983953,\n",
    "        947.62620298,\n",
    "        1199.47283961,\n",
    "        1999.79090914,\n",
    "        2369.22292565,\n",
    "        2296.82608323,\n",
    "        732.08340178,\n",
    "        12.11327804,\n",
    "        1819.01027855,\n",
    "        1118.92391149,\n",
    "        2594.14080798,\n",
    "    ]\n",
    ")\n",
    "\n",
    "band_stds = torch.tensor(\n",
    "    [\n",
    "        245.71762908,\n",
    "        333.00778264,\n",
    "        395.09249139,\n",
    "        593.75055589,\n",
    "        566.4170017,\n",
    "        861.18399006,\n",
    "        1086.63139075,\n",
    "        1117.98170791,\n",
    "        404.91978886,\n",
    "        4.77584468,\n",
    "        1002.58768311,\n",
    "        761.30323499,\n",
    "        1231.58581042,\n",
    "    ]\n",
    ")\n",
    "\n",
    "#band_means = band_means[[3,2,1]]\n",
    "#band_stds = band_stds[[3,2,1]]\n",
    "\n",
    "min_value = (band_means - 2 * band_stds).unsqueeze(1).unsqueeze(2)\n",
    "max_value = (band_means + 2 * band_stds).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "norm = Normalize(band_means, band_stds)\n",
    "\n",
    "# def preprocess(sample):\n",
    "#     img = sample[\"image\"].float()\n",
    "#     img = (img - min_value) / (max_value - min_value)\n",
    "#     sample[\"image\"] = torch.clip(img, 0, 1)\n",
    "#     return sample\n",
    "\n",
    "def preprocess(sample):\n",
    "    sample[\"image\"] = (sample[\"image\"].float() / 10000.0)\n",
    "    return sample\n",
    "\n",
    "\n",
    "train_ds = EuroSAT(\n",
    "    root=\"data/EuroSAT/\",\n",
    "    split=\"train\",\n",
    "    bands=EuroSAT.BAND_SETS[\"all\"],\n",
    "    transforms=preprocess,\n",
    ")\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=False, num_workers=6)\n",
    "\n",
    "\n",
    "test_ds = EuroSAT(\n",
    "    root=\"EuroSAT/\",\n",
    "    split=\"test\",\n",
    "    bands=EuroSAT.BAND_SETS[\"all\"],\n",
    "    transforms=preprocess,\n",
    ")\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e70969a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader, device):\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].numpy()\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            features = model(images)['global_pool'].cpu().numpy()\n",
    "        \n",
    "        x_all.append(features)\n",
    "        y_all.append(labels)\n",
    "\n",
    "    x_all = np.concatenate(x_all, axis=0)\n",
    "    y_all = np.concatenate(y_all, axis=0)\n",
    "\n",
    "    return x_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d27ce9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 169/169 [00:06<00:00, 27.85it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = extract_features(model, train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d57e65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 169/169 [00:05<00:00, 29.49it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = extract_features(model, test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2304e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=50.0, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=50.0, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=50.0, max_iter=1000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LogisticRegression(C=50.0, max_iter=1000)\n",
    "linear_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d53ee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9829629629629629"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61b0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
